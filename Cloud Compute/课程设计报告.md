# 基于 Hadoop 架构 使用 Map Reduce 算法的数据统计

- 出于好奇心，想了解英文名字中字母出现频率以及中文名字中汉字的出现频率，我设计了本次实验，来统计 2万 英文名字以及 120 万中文名字中字母以及汉字的出现频率。( 已包括大多数常见名字 )

## Hadoop

### 什么是 Hadoop 架构

- [引自百度百科](https://baike.baidu.com/item/Hadoop)
- Hadoop是一个由Apache基金会所开发的分布式系统基础架构。
- 用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。
- Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。
- Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。

### HDFS 工作原理(1.x)

- [参考博客](http://www.daniubiji.cn/archives/596)
- HDFS 特点
  - 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。
  - 运行在廉价的机器上。（商用机）
  - 适合大数据的处理。HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。**2.x版本后**变为128M为1个block，是为了减少namenode压力,因为block size大了,对应收到的元数据个数就会减少一些,namenode可以更加专注的干它所负责的事情。
  ![](https://github.com/Chris-Ju/Picture/blob/master/HDFSMasterSlave.jpg?raw=true)
  - 如上图所示，HDFS是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。
  - NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；
  - SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。
  - DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。
  - 热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。
  - 冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。

![](https://github.com/Chris-Ju/Picture/blob/master/HDFS%E5%8E%9F%E7%90%86.jpg?raw=true)

- 写操作
  - 有一个文件FileA，100M大小。Client将FileA写入到HDFS上。
  - HDFS按默认配置。
  - HDFS分布在三个机架上Rack1，Rack2，Rack3。
  - a. Client将FileA按64M分块。分成两块，block1和Block2;
  - b. Client向nameNode发送写数据请求，如图蓝色虚线;
  - c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线。
  - Block1: host2,host1,host3
  - Block2: host7,host8,host4
    - 原理：
      - NameNode具有RackAware机架感知功能，这个可以配置。
      - 若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。
      - 若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。

  - d. client向DataNode发送block1；发送过程是以流式写入。
  - 流式写入过程，
    - 1>将64M的block1按64k的package划分;
    - 2>然后将第一个package发送给host2;
    - 3>host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；
    - 4>host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。
    - 5>以此类推，如图红线实线所示，直到将block1发送完毕。
    - 6>host2,host1,host3向NameNode，host2向Client发送完成通知。如图粉红颜色实线所示。
    - 7>client 收到 host2发来的消息后，向namenode发送已完成消息。如图黄色粗实线
    - 8>发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。
    - 9>发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。
    - 10>client向NameNode发送完成消息，如图黄色粗实线，写操作结束。
- 读操作
  - 如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。
  - a. client向namenode发送读请求。
  - b. namenode查看Metadata信息，返回fileA的block的位置。
    - block1:host2,host1,host3
    - block2:host7,host8,host4
  - c. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；
- 上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：优选读取本机架上的数据。

## Map Reduce

### 什么是 Map Reduce

- [引自百度百科](https://baike.baidu.com/item/MapReduce)
- MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念"Map（映射）"和"Reduce（归约）"，是它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。

### Map Reduce 工作原理

- [参考博客](https://blog.csdn.net/recommender_system/article/details/42024205)

![](https://github.com/Chris-Ju/Picture/blob/master/MapReduce.jpg?raw=true)

- MapReduce模型如上图所示，Hadoop MapReduce模型主要有Mapper和Reducer两个抽象类。Mapper端主要负责对数据的分析处理，最终转化为Key-Value的数据结构；Reducer端主要是获取Mapper出来的结果，对结果进行统计。

![](https://github.com/Chris-Ju/Picture/blob/master/MapReduce%E5%8E%9F%E7%90%86.jpg?raw=true)

- 整个过程如上图所示，包含4个独立的实体，如下所示：
  - client：提交MapReduce作业，比如，写的MR程序，还有CLI执行的命令等。
  - jobtracker：协调作业的运行，就是一个管理者。
  - tasktracker：运行作业划分后的任务，就是一个执行者。
  - hdfs：用来在集群间共享存储的一种抽象的文件系统。

## 实验过程

- 利用VMware架设虚拟机集群，虚拟机使用 ubuntu server 14.04, 在每台虚拟机上单独配置SSH免登陆、jdk、hadoop平台环境。
- 编写 Map Reduce 函数代码
- 上传需要处理的数据
- 数据处理
- 得出结果并下载到本地

## 实验结果

![](https://github.com/Chris-Ju/Picture/blob/master/LetterInEnglishName.png?raw=true)
![](https://github.com/Chris-Ju/Picture/blob/master/LetterInChineseName.png?raw=true)

- 详细结果在代码包的文件中